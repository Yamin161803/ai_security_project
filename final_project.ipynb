{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project\n",
    "\n",
    "Philip Wolls√©n Ervius \\\n",
    "phao21@student.bth.se\n",
    "\n",
    "Amin Afzali \\\n",
    "moaf@student.bth.se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 162,
=======
   "execution_count": 23,
   "execution_count": 1,
>>>>>>> 4afb08c2a05ec6f03fe56844a2a5b7b58b3120d6
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import CrossEntropyLoss, Linear\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations\n",
    "The CIFAR-10 dataset will be transformed to fit the ImageNet-1k data it was pretrained on."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 163,
=======
   "execution_count": 24,
   "execution_count": 2,
>>>>>>> 4afb08c2a05ec6f03fe56844a2a5b7b58b3120d6
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for CIFAR-10 (resize and normalize to match ImageNet-1K pretraining)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    # transforms.Resize(256),       # Resize to 256px on the shorter side\n",
    "    # transforms.CenterCrop(224),   # Center crop to 224x224\n",
    "    transforms.ToTensor(),        # Convert to tensor\n",
    "    # transforms.Normalize(\n",
    "    # mean=[0.485, 0.456, 0.406],  # ImageNet mean\n",
    "    # std=[0.229, 0.224, 0.225]    # ImageNet std\n",
    "    # ),\n",
    "])\n",
    "\n",
    "\n",
    "to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),        # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the CIFAR-10 dataset\n",
    "\n",
    "We will split the dataset into training and test partitions. Then, we get a subset from the test partition to use for attacks, since they will be new to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CIFAR10(root=\"./data\", train=True,\n",
    "                        transform=preprocess, download=True)\n",
    "full_test_dataset = CIFAR10(\n",
    "    root=\"./data\", train=False, transform=preprocess, download=True)\n",
>>>>>>> 4afb08c2a05ec6f03fe56844a2a5b7b58b3120d6
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "nr_of_attack_images = 1000\n",
    "\n",
    "test_dataset = Subset(full_test_dataset, range(\n",
    "    nr_of_attack_images, len(full_test_dataset)))\n",
    "attack_dataset = Subset(full_test_dataset, range(nr_of_attack_images))\n",
    "\n",
    "attack_loader = DataLoader(attack_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dict with the names for each label"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 165,
=======
   "execution_count": 5,
>>>>>>> 4afb08c2a05ec6f03fe56844a2a5b7b58b3120d6
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained model\n",
    "\n",
    "We will be using a pretrained model gotten from the public repository https://github.com/chenyaofo/pytorch-cifar-models?tab=readme-ov-file. It is a fine-tuned Moblienet-V2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\",\n",
    "                       \"cifar10_mobilenetv2_x0_5\", pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 167,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model):\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.append(labels)\n",
    "            all_predictions.append(predicted)\n",
    "\n",
    "    # Concatenate all tensors\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    all_predictions = torch.cat(all_predictions).numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_images(images: list, classify=None, extra_info=None, fig_title=None):\n",
    "    \"\"\"Displays a list of images.\n",
    "\n",
    "    Parameters:\n",
    "        - images: list of torch images.\n",
    "        - classify: Optional bool whether to classify images using model.\n",
    "        - extra_info: Optional dict[int, str] or list[str] containing extra information\n",
    "                                to be displayed for certain images.\n",
    "        - fig_title: Optional figure title.\n",
    "    \"\"\"\n",
    "\n",
    "    if not images:\n",
    "        return\n",
    "\n",
    "    max_cols = 5\n",
    "\n",
    "    if len(images) >= max_cols:\n",
    "        cols = max_cols\n",
    "    else:\n",
    "        cols = len(images) % max_cols\n",
    "\n",
    "    rows = len(images) // cols\n",
    "\n",
    "    if rows * cols < len(images):\n",
    "        rows += 1\n",
    "\n",
    "    width = 3.8*cols\n",
    "    height = 3.2*rows\n",
    "    if fig_title:\n",
    "        height += 2.8\n",
    "\n",
    "    if cols <= 2:\n",
    "        width *= 1.7\n",
    "        height *= 1.7\n",
    "    elif cols == 3:\n",
    "        width *= 1.5\n",
    "        height *= 1.5\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    axes = fig.subplots(nrows=rows, ncols=cols)\n",
    "\n",
    "    if rows == 1 and cols == 1:                 # Make sure axes is always 2D for indicing\n",
    "        axes = np.array([[axes]])\n",
    "    elif rows == 1 or cols == 1:\n",
    "        axes = np.array(axes).reshape(rows, cols)\n",
    "    else:\n",
    "        axes = np.array(axes)\n",
    "\n",
    "    to_pil_image = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "    for i in range(rows * cols):\n",
    "\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "\n",
    "        if i >= len(images):\n",
    "            fig.delaxes(axes[row][col])\n",
    "            continue\n",
    "\n",
    "        img = images[i]\n",
    "\n",
    "        if len(img.shape) == 4:\n",
    "            disp_img = to_pil_image(img.squeeze(0).permute(1, 2, 0))\n",
    "        else:\n",
    "            disp_img = to_pil_image(img)\n",
    "\n",
    "        axes[row][col].imshow(disp_img)\n",
    "\n",
    "        title = \"\"\n",
    "\n",
    "        if classify:\n",
    "            with torch.no_grad():\n",
    "                output = model(to_tensor(img).unsqueeze(0))\n",
    "\n",
    "            _, pred = torch.max(output, 1)\n",
    "            title = f\"Predicted: {class_names[pred.item()]}\"\n",
    "        if extra_info:\n",
    "            try:\n",
    "                title += f\"{extra_info[i]}\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        axes[row][col].set_title(title)\n",
    "        axes[row][col].axis('off')\n",
    "\n",
    "    fig.patch.set_facecolor(\"lightgray\")\n",
    "\n",
    "    if fig_title:\n",
    "        fig.suptitle(fig_title, fontsize=28)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(img, label):\n",
    "    \"\"\"Trains the model on an image.\n",
    "\n",
    "    Parameters:\n",
    "        - img: tensor of preprocessed image.\n",
    "        - label: int target label for the image.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(img.shape) == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.001)\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Prepare the input and label\n",
    "    labels = torch.tensor([label])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(img)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    # print(f'Loss: {running_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack #1: Backdoor trigger\n",
    "\n",
    "We will pick a set of images and add a couple trigger pixels. The goal is for the model to associate the pixels with a certain class, allowing us to achieve the desired output for any image with the trigger in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_poisoned_pixels = 1\n",
    "indices = np.random.randint(0, 32, [nr_of_poisoned_pixels, 2])\n",
    "\n",
    "poison_strength = 10     # Pixel values\n",
    "target_label = 0        # Airplane\n",
    "channel = 1             # Green\n",
    "\n",
    "\n",
    "class PoisonTransform:\n",
    "    def __init__(self, indices, value, channel):\n",
    "        self._indices = indices\n",
    "        self._poison_value = value\n",
    "        self._channel = channel\n",
    "\n",
    "    def __call__(self, image):\n",
    "        for (x, y) in self._indices:\n",
    "            image[self._channel, x, y] = self._poison_value\n",
    "        return image\n",
    "\n",
    "\n",
    "backdoor_dataset = [(PoisonTransform(indices, poison_strength, channel)(\n",
    "    image), target_label) for image, label in attack_dataset if label != target_label]\n",
    "\n",
    "attack_samples = []\n",
    "attack_labels = []\n",
    "\n",
    "# For training the model\n",
    "nr_of_attack_images = min(len(backdoor_dataset), 100)\n",
    "\n",
    "for (image, label), i in zip(backdoor_dataset, range(nr_of_attack_images)):\n",
    "    attack_samples.append(image.permute(1, 2, 0).numpy())\n",
    "    attack_labels.append(label)\n",
    "\n",
    "nr_of_examples = 10\n",
    "display_images(attack_samples[:nr_of_examples], extra_info=[\n",
    "               f\"Original class: {class_names[label]}\" for _, label in attack_dataset if label != target_label], fig_title=\"Poisoned images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on the poisoned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (image, _), label in zip(backdoor_dataset, attack_labels):\n",
    "    train(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate attack efficiency and model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attack_test_samples = []\n",
    "for (image, label), i in zip(backdoor_dataset, range(nr_of_attack_images, len(backdoor_dataset))):\n",
    "    attack_test_samples.append(image.permute(1, 2, 0).numpy())\n",
    "\n",
    "    if i > 1000:\n",
    "        break\n",
    "\n",
    "success = 0\n",
    "with torch.no_grad():\n",
    "    for image in attack_test_samples:\n",
    "\n",
    "        output = model(to_tensor(image).unsqueeze(0))\n",
    "\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "        if pred.item() == target_label:\n",
    "            success += 1\n",
    "\n",
    "success_rate = success / len(attack_test_samples)\n",
    "print(f\"Backdoor attack success rate: {success_rate}\")\n",
    "\n",
    "display_images(\n",
    "    attack_test_samples[nr_of_attack_images:nr_of_attack_images+10], classify=True)\n",
    "\n",
    "print(\"\\nModel evaluation after attack:\")\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defence #1: Statistical analysis\n",
    "We start by analysing the training data to determine its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(dataloader):\n",
    "\n",
    "    all_pixels = []\n",
    "\n",
    "    for inputs, _ in dataloader:\n",
    "        if len(inputs.size()) == 4 and inputs.size(0) == dataloader.batch_size:\n",
    "            all_pixels.append(inputs.view(inputs.size(0), inputs.size(1), -1))\n",
    "\n",
    "    all_pixels = torch.cat(all_pixels, dim=2)\n",
    "\n",
    "    mean = all_pixels.mean(dim=(0, 2))\n",
    "    std = all_pixels.std(dim=(0, 2))\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "train_mean, train_std = calculate_mean_std(train_loader)\n",
    "\n",
    "print(\n",
    "    f\"Training dataset distribution of RGB values:\\nMean: {train_mean}\\nStd:  {train_std}\")\n",
    "\n",
    "\n",
    "def is_outlier(image, threshold=3.0):\n",
    "    \"\"\"Determines whether a tensor image is a statistical outlier.\n",
    "\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "\n",
    "        image: Input tensor of shape [3, 32, 32].\n",
    "\n",
    "\n",
    "        threshold: float Z-score threshold to consider as an outlier (default: 3.0).\n",
    "\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "\n",
    "        bool: True if the image is an outlier, False otherwise.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    normalized_image = (image - train_mean.view(3, 1, 1)) / \\\n",
    "        train_std.view(3, 1, 1)\n",
    "\n",
    "\n",
    "    max_z_score = torch.abs(normalized_image).max()\n",
    "\n",
    "\n",
    "    return bool(max_z_score > threshold)\n",
    "\n",
    "\n",
    "\n",
    "fp_outliers = 0\n",
    "\n",
    "\n",
    "for i, (image, _) in enumerate(train_dataset):\n",
    "\n",
    "\n",
    "    if is_outlier(image):\n",
    "\n",
    "\n",
    "        fp_outliers += 1\n",
    "\n",
    "\n",
    "    if i > len(backdoor_dataset):\n",
    "\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "tp_outliers = 0\n",
    "\n",
    "\n",
    "for image, _ in backdoor_dataset:\n",
    "\n",
    "\n",
    "    if is_outlier(image):\n",
    "\n",
    "\n",
    "        tp_outliers += 1\n",
    "\n",
    "\n",
    "\n",
    "print(f\"True Positive: {tp_outliers} out of {len(backdoor_dataset)}\")\n",
    "\n",
    "\n",
    "print(f\"False Positives: {fp_outliers} out of {len(backdoor_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD attack function\n",
    "def pgd_attack(model, data, target, epsilon=0.01, alpha=0.005, num_steps=40):\n",
    "    # Create a copy of the input to modify it\n",
    "    original_data = data.clone().detach()\n",
    "    perturbed_data = original_data.clone().detach().requires_grad_(True)\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        output = model(perturbed_data)\n",
    "        loss = nn.CrossEntropyLoss()(output, target)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Apply PGD update step\n",
    "        with torch.no_grad():\n",
    "            perturbed_data = perturbed_data + alpha * \\\n",
    "                perturbed_data.grad.sign()  # Perturb the image\n",
    "            perturbed_data = torch.min(\n",
    "                torch.max(perturbed_data, original_data - epsilon),\n",
    "                original_data + epsilon\n",
    "            )  # Clip the perturbed image\n",
    "            # Ensure pixel values are in [0, 1]\n",
    "            perturbed_data = torch.clamp(perturbed_data, 0, 1)\n",
    "\n",
    "        # Re-enable gradient computation for the next step\n",
    "        perturbed_data.requires_grad_(True)\n",
    "\n",
    "    return perturbed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "defence_preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomPerspective(distortion_scale=0.08, p=1.0, fill=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.05, 0.3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.003),\n",
    "])\n",
    "\n",
    "\n",
    "def preprocess_input(data):\n",
    "    return torch.stack([defence_preprocess(img) for img in data])\n",
    "    return torch.tensor(median_filter(data.numpy(), size=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adv_images = []\n",
    "data_images = []\n",
    "i = 0\n",
    "end = 10\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    data_images.append(data)\n",
    "    all_adv_images.append(pgd_attack(model, images, labels))\n",
    "    i += 1\n",
    "    if i >= end:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adv_evaluate(model, data_images, all_adv_images, end=10):\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_adv_predictions = []\n",
    "    all_adv_transform_predictions = []\n",
    "    total_amount = 32*(end+1)\n",
    "\n",
    "    i = 0\n",
    "    print(\"Attack done\")\n",
    "    with torch.no_grad():\n",
    "        # for images, labels in test_loader:\n",
    "        for adv_images, data in zip(all_adv_images, data_images):\n",
    "            # for data in test_loader:\n",
    "            images, labels = data\n",
    "            attack_amount = 0\n",
    "            outputs = model(images)\n",
    "            _, predicted1 = torch.max(outputs, 1)\n",
    "            all_labels.append(labels)\n",
    "            all_predictions.append(predicted1)\n",
    "\n",
    "            outputs = model(adv_images)\n",
    "            _, predicted2 = torch.max(outputs, 1)\n",
    "            all_adv_predictions.append(predicted2)\n",
    "\n",
    "            outputs = model(preprocess_input(adv_images))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_adv_transform_predictions.append(predicted)\n",
    "\n",
    "            # showList(images)\n",
    "    # Concatenate all tensors\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    all_predictions = torch.cat(all_predictions).numpy()\n",
    "    all_adv_predictions = torch.cat(all_adv_predictions).numpy()\n",
    "    all_adv_transform_predictions = torch.cat(\n",
    "        all_adv_transform_predictions).numpy()\n",
    "\n",
    "    all_labels = all_labels[0:32 * (end + 1)]\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    adv_accuracy = accuracy_score(all_labels, all_adv_predictions)\n",
    "    adv_transform_accuracy = accuracy_score(\n",
    "        all_labels, all_adv_transform_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "    adv_f1 = f1_score(all_labels, all_adv_predictions, average='macro')\n",
    "    adv_transform_f1 = f1_score(\n",
    "        all_labels, all_adv_transform_predictions, average='macro')\n",
    "\n",
    "\n",
    "    print(f\"Amount : {total_amount}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Adv Accuracy: {adv_accuracy}\")\n",
    "    \n",
    "    print(f\"Adv transform Accuracy: {adv_transform_accuracy}\")\n",
    "    \n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Adv F1 Score: {adv_f1}\")\n",
    "    print(f\"Adv transform F1 Score: {adv_transform_f1}\")\n",
    "\n",
    "def calculate_mean_std(dataloader):\n",
    "    all_pixels = []\n",
    "\n",
    "    for inputs, _ in dataloader:\n",
    "        if len(inputs.size()) == 4 and inputs.size(0) == dataloader.batch_size:\n",
    "            all_pixels.append(inputs.view(inputs.size(0), inputs.size(1), -1))\n",
    "\n",
    "    all_pixels = torch.cat(all_pixels, dim=2)\n",
    "\n",
    "    mean = all_pixels.mean(dim=(0, 2))\n",
    "    std = all_pixels.std(dim=(0, 2))\n",
    "    return mean, std\n",
    "\n",
    "train_mean, train_std = calculate_mean_std(train_loader)\n",
    "\n",
    "print(f\"Training dataset distribution of RGB values:\\nMean: {train_mean}\\nStd:  {train_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding outliers\n",
    "If an image is an outlier then it may be poisoned. By detecting these images, we can counteract the attack. The rationale is that poisoned images will have a different distribution of RGB values, or contain extreme values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
