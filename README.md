# Kapprustningen inom AI säkerhet

Vi vill fördjupa vår förståelse för AI-säkerhet samtidigt som vi skaffar oss praktisk erfarenhet inom området. För att uppnå detta vill vi genomföra ett experiment som utforskar ett antal olika attacker och försvarsmetoder i form av en kontrollerad kapprustning. 

Forskningsfrågorna vi undersöker är:
- Vilken effekt har olika attacker på en bildklassificeringsmodell?
- Hur kan olika försvarsmetoder lindra inverkan av attacker på en modell?
- Vilka metoder kan användas för att upptäcka och identifiera olika attacker?
- Hur kan attackmetoder kringgå de försvarsmetoder som används mot dem?

För detta experiment kommer vi att implementera försvars -och attackmetoder för en modell. Vi planerar att dokumentera varje steg i experimentet, inklusive hur både attacker och skyddsmekanismer utvecklas och förändras över tid. Vi siktar på att implementera en attack eller försvarsmetod per vecka, i ca 3-4 iterationer. Därefter kommer vi att fokusera på analysen av datan vi samlat in, utvärdera resultaten av experimentet och skriva rapporten.